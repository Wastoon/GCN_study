# Can GNN go “online”?an analysis of pretraining and inference

## 0 引言

目前，GCN 及其变体（例如：[GCN](https://archwalker.github.io/blog/2019/06/01/GNN-Triplets-GCN.html)、[GraphSAGE](https://archwalker.github.io/blog/2019/06/01/GNN-Triplets-GraphSAGE.html)、[GAT](https://archwalker.github.io/blog/2019/06/01/GNN-Triplets-GAT.html)）在图结构数据的学习方面都取得了不错的效果，特别是采用 [Transductive learning](https://archwalker.github.io/blog/2019/06/01/GNN-Triplets-GraphSAGE.html) 学习方式时，即测试集和验证集在训练的时候是可见的情况下。

然而，在很多实际应用中，大规模图结构数据通常不是静态的而是动态的，即随着时间的的推移会出现新的节点和边插入，例如社交网络，引文网络或者一些在线图结构数据应用。

本篇博文将为大家介绍该问题，以及通过对比实验对改问题进行分析与总结。该博文主要来自论文 [Can GNN go “online”?an analysis of pretraining and inference](https://arxiv.org/pdf/1905.06018)，该论文重点讨论以下问题：

1. 如果向已知的节点和边的图结构中加入未知节点和边，使用预训练的 GNN 模型进行训练和从头开始重新训练模型，哪一种方式效果更好？

## 1 动机

虽然 GNN 模型及其变体在图结构数据的学习方面取得了成功，但是 GNNs 所采用的学习方式大多都是 Transductive learning 学习方式，该学习方式主要特点是在训练图结构节点数据收集邻居信息的时候，会用到了测试或者验证样本。

然而，在很多实际应用中，大规模图结构数据每个时候都在发生变化，即每个时候都有可能有新的节点或边插入图结构数据中。举个例子，在推荐系统中，每个时段都会有新的用户（节点）或新的关系（边）加入原有关系网络中，而这些新的用户（节点）或新的关系（边）都会对已训练好的模型造成一定的影响。

目前研究的大多数 GNN 模型及其变体都缺乏推理能力的潜在缺点。即每当有新的节点或边插入时，已训练好的模型不具备有预测未知节点或边的能力。因此，一般会采取以下两种方式：

1. 从头开始重新训练模型，因为需要消耗大量的人力物力资源，所以该方法的代价是昂贵的；
2. 在带标签的已知图结构数据进行预训练，然后使用预训练模型进行少量推理步骤的可能性，但目前尚未对这种方式进行评估，即无法判断预训练模型是否是处理图结构数据中更新的有效方法。


## 2、实验方法

为了评估上述两种方法，论文提出了一组对比实验：

- 对于从头开始重新训练模型。每次训练都在推理期间开始，相当于每当插入新节点和边时都需要从头开始重新训练。
- 预训练模型。该训练过程可以分为以下两步：
  
  (1)、 在带标签的训练集中预训练模型；

  (2)、 将不可见的节点和边插入到图中，并对预模型模型进行有限量的参数更新。


最后，对于每个模型，我们使用200个预训练时期与没有预训练进行比较。分析训练模型在每个推理时期之后的测试准确性，并对带有预训练的网络性能和未预训练的网络性能进行评估与比较。


## 3、实验数据集

论文所用的三个标注引用数据集分别为：Cora, Citeseer, and Pubmed，其中，文本特征和带有类别标签用节点表示，引用关系用边表示。为了使这些数据集能够用于 Inductive learn学习方式，论文设置了一些不可见节点。

![dataset](img/dataset.png)


## 4、实验组设置

如下图所示，论文对每个数据集采用不同的 train-test 分割：

Few-many setup (A)：由一些标记的节点组成，这些节点可以推理训练集和许多未标记的节点。

many-few setup (B)：包括许多训练节点和很少的测试节点。通过反转 setup A 的 train-test mask 进行设置，并相应地分配边。设置B的动机来自应用程序，其中已知大图并且随时间发生增量变化，例如引用推荐，社交网络中的链接预测等。

![](img/setup.png)

# 5、实验结果

三个模型在三个数据集上的实验结果如下图所示：

![](img/result1.png)

预训练模型的得分始终高于非预训练模型，同时方差明显较小。 在几个推断时期之后（在Cora-A和Pubmed-B上高达10），预训练模型的准确性稳定。 没有任何预训练，GAT显示了最快的学习过程。 预训练图神经网络的绝对分数高于MLP。 从广义的角度来看，预训练图神经网络的得分都处于同一水平。 虽然GCN在Cora-B上落后于其他的，但GAT在Pubmed上落后于其他的。

许多设置B的绝对分数高于少数设置A的绝对分数。 我们通过测量精确度分布之间的Jensen-Shannon散度来全局比较设置A和B的结果。 两种设置之间的Jenson-Shannon偏差在预训练时较低（GAT为0.0057，MLP为0.0115），而没有预训练（GraphSAGE为0.0666，GCN为0.1013）。

# 6、实验结论

通过设计一对对比试验来评估图神经网络的推理能力，采用引用图数据集进行归纳实验：Cora，Citeseer和Pubmed。

结果表明，预先训练的模型在看不见的节点上产生高精度分数，并且预训练优于从头开始重新训练。预训练模型的低方差表明，每个预训练模型的100次运行收敛以产生类似的准确度分数，并且它们对于添加看不见的节点是鲁棒的。
